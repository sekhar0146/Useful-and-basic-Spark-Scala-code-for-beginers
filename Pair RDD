package ClassExamples

import org.apache.spark.sql.SparkSession

object Spark_RDD_ParRDD {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("Spark basic example")
      .config("spark.master", "local")
      .getOrCreate()
    spark.sparkContext.setLogLevel("error")
    // creation of rdd
    val rd1 = spark.sparkContext.parallelize(Array((1,2),(3,2),(1,4),(3,5),(4,6)))
    val rddmulti = rd1.map(x => (x._1*x._1, x._2*x._2))
    rddmulti.collect().foreach(println)

    println(" ")

    // keys and values added together
    val addkeyval = rd1.reduce((a,b) => (a._1+b._1 , a._2+b._2))
    println(addkeyval)
  }

}

//* Output
(1,4)
(9,4)
(1,16)
(9,25)
(16,36)
 
(12,19)
